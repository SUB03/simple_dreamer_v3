# training
seed: 42
logdir: runs
episodes_before_start: 5
grad_steps: 60000
replay_ratio: 16
action_repeats: 1
batch_size: 16
batch_length: 32
capacity: 50000

imagination_horizon: 10
discount: 0.99
gamma: 0.99
lmbda: 0.95
unimix: 0.01
free_nats: 1.0
entropyScale: 0.0003
bins: 255
reward_min: -20
reward_max: 20

latent_a: 32 # categories
latent_b: 32 # classes

recurrent_model:
  deter_size: 256

world_model:

  # optimizer
  lr: 3e-4
  b1: 0.9
  b2: 0.999

actor:
  num_layers: 2
  hidden_dim: 256

  ent_coef: 1e-3

  # optimizer 
  eps: 1e-5
  lr: 3e-4
  b1: 0.9
  b2: 0.999

critic:
  num_layers: 2
  hidden_dim: 256
  bins: 255
  target_network_update_freq: 1
  tau: 0.02

  # optimizer
  lr: 3e-4
  b1: 0.9
  b2: 0.999
